---
title: "Machine Learning with tidymodels"
author: "Murad Khalilov"
date: "11/05/2020"
output: beamer_presentation
urlcolor: blue
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, tidy = FALSE)
```

## Tidymodels suite
```{r echo=FALSE, message=FALSE, fig.show='hold', fig.align='center', out.width="30%"}
library(here)
library(conflicted)
library(patchwork)

knitr::include_graphics(here("images/tidymodels.png"))
```

```{r echo=FALSE, message=FALSE, fig.show="hold", fig.align='center', out.width="15%"}
knitr::include_graphics(c(
  here("images/rsample.png"),
  here("images/recipes.png"),
  here("images/parsnip.png"),
  here("images/tune.png"),
  here("images/yardstick.png")))
```

## Titanic
```{r echo=FALSE, message=FALSE, fig.align='center', out.width="80%"}
knitr::include_graphics(here("images/titanic.jpg"))
```

## Titanic data
\tiny
```{r message=FALSE}
library(here)
library(tidyverse)
library(tidymodels)
library(janitor)

titanic <- read_csv(here("input/train.csv")) %>%
  clean_names() %>%
  mutate(survived = as_factor(survived)) %>%
  select(survived, everything())

glimpse(titanic)
```

```{r message=FALSE, echo=FALSE, warning=FALSE}
mr <- c("Don", "Major", "Capt", "Jonkheer", "Rev", "Col", "Sir")
mrs <- c("Countess", "Mme", "Lady")
miss <- c("Mlle", "Ms")

mydf <- titanic %>%
  mutate(title = str_extract(name, "\\w+?(?=\\.)"),
    title = as_factor(case_when(
      title %in% mr ~ "Mr",
      title %in% mrs ~ "Mrs",
      title %in% miss ~ "Miss",
      title == "Dr" & sex == "male" ~ "Mr",
      title == "Dr" & sex == "female" ~ "Mrs",
      TRUE ~ title)),
    title = fct_relevel(title, "Master", "Mrs", "Miss", "Mr"),
    cabin = substr(str_remove_all(cabin, "[^a-zA-Z]"), 1, 1)
    )

theme_set(theme_minimal())

plot_histogram <- function(df, x, fill, subtitle) {
  df %>%
    ggplot(aes(x = {{ x }}, fill = {{ fill }})) +
    geom_histogram(position = "identity", alpha = .7) +
    theme(axis.title = element_blank()) +
    labs(subtitle = subtitle)
}

plot_cdf <- function(df, x, colour, subtitle) {
  df %>%
    ggplot(aes(x = {{ x }}, col = {{ colour }})) +
    stat_ecdf(pad = F) +
    theme(axis.title = element_blank()) +
    labs(subtitle = subtitle)
}

p1 <- mydf %>%
  count(survived) %>%
  ggplot(aes(x = reorder(survived, n), y = n, fill = survived)) +
  geom_col() +
  coord_flip() +
  theme(axis.title = element_blank(), legend.position = "none") +
  labs(subtitle = "Balance of the outcome variable")

p2 <- mydf %>%
  count(pclass, survived) %>%
  ggplot(aes(x = pclass, y = n, fill = survived)) +
  geom_col(position = "dodge") +
  coord_flip() +
  theme(axis.title = element_blank()) +
  labs(subtitle = "Survival rate across passenger classes")

p3 <- mydf %>%
  count(title, survived) %>%
  ggplot(aes(x = reorder(title, n), y = n, fill = survived)) +
  geom_col(position = "dodge") +
  coord_flip() +
  theme(axis.title = element_blank()) +
  labs(subtitle = "Survival rate across titles")

p4 <- mydf %>%
  dplyr::filter(is.na(age)) %>%
  count(title) %>%
  ggplot(aes(x = title, y = n)) +
  geom_col() +
  coord_flip() +
  theme(axis.title = element_blank()) +
  labs(subtitle = "# of missing age observations")

p5 <- mydf %>%
  dplyr::filter(!is.na(age)) %>%
  ggplot(aes(x = title, y = age)) +
  geom_boxplot(outlier.alpha = .5) +
  coord_flip() +
  theme(axis.title = element_blank(), axis.text.y = element_blank()) +
  labs(subtitle = "Age distribution")

p6 <- plot_histogram(mydf, x = age, fill = survived, 
                     subtitle = "Age distribution")
p7 <- plot_cdf(mydf, x = age, col = survived, 
               subtitle = "CDF of the age variable")
p8 <- plot_histogram(mydf, x = fare, fill = survived, 
                     subtitle = "Fare distribution")
p9 <- plot_cdf(mydf, x = fare, colour = survived, 
               subtitle = "CDF of the fare variable")
```

## EDA
```{r message=FALSE, echo=FALSE, warning=FALSE, fig.align='center', out.width='90%'}
p1 + p2 + p4 + p5
```

## EDA
```{r message=FALSE, echo=FALSE, warning=FALSE, fig.align='center', out.width='90%'}
p6 + p7 + p8 + p9
```

## Train test split
```{r echo=FALSE}
knitr::include_graphics(here("images/train_test_split.png"))
```


## Train test split
\tiny
```{r train_test_split, message=FALSE}
train_test_splits <- initial_split(titanic, prop = 0.75, strata = survived)
train_test_splits

training_data <- training(train_test_splits)
nrow(training_data)

testing_data <- testing(train_test_splits)
nrow(testing_data)
```

## Data preprocessing or baking cupcakes
```{r echo=FALSE}
knitr::include_graphics(here("images/hadley_cupcakes.jpg"))
```

## Recipes workflow
\tiny

1) **Get the ingredients (recipe())**: specify the response variable and 
predictor variables

2) **Write the recipe (step_zzz())**: define the pre-processing steps, 
such as imputation, creating dummy variables, scaling, and more

3) **Prepare the recipe (prep())**: provide a dataset to base each step on 
(e.g. if one of the steps is to remove variables that only have one unique 
value, then you need to give it a dataset so it can decide which variables 
satisfy this criteria to ensure that it is doing the same thing to every 
dataset you apply it to)

4) **Bake the recipe (bake())**: apply the pre-processing steps to your 
datasets

^[http://www.rebeccabarter.com/blog/2019-06-06_pre_processing/]

## Define the recipe/blueprint
\tiny
```{r message=FALSE}

mr <- c("Don", "Major", "Capt", "Jonkheer", 
        "Rev", "Col", "Sir")
mrs <- c("Countess", "Mme", "Lady")
miss <- c("Mlle", "Ms")

blueprint <- recipe(survived ~ ., data = training_data) %>%
  step_mutate(
    pclass = as_factor(pclass),
    sex = as_factor(sex),
    title = str_extract(name, "\\w+?(?=\\.)"),
    title = case_when(
      title %in% mr ~ "Mr",
      title %in% mrs ~ "Mrs",
      title %in% miss ~ "Miss",
      title == "Dr" & sex == "male" ~ "Mr",
      title == "Dr" & sex == "female" ~ "Mrs",
      TRUE ~ title),
    ) %>%
  # impute age using titles (groupwise imputation)
  step_bagimpute(age, impute_with = "title") %>%
  # drop columns
  step_rm("passenger_id", "name", "sib_sp", "parch", "ticket", 
          "cabin", "embarked", "title") %>%
  step_center(all_numeric(), -all_outcomes()) %>%
  step_scale(all_numeric(), -all_outcomes()) %>%
  step_dummy(all_nominal(), -all_outcomes(), one_hot = F) %>%
  step_nzv(all_predictors())
```

## Prepare the recipe
\tiny
```{r}
# fit the recipe to the training data
prepped <- prep(blueprint, training = training_data, strings_as_factors = T)
prepped
```

## Apply preprocessing steps - juice and bake
\tiny
```{r}
# transform the training data
juiced_train <- juice(prepped)
juiced_train
```

## Apply preprocessing steps - juice and bake
\tiny
```{r}
# transform the testing data
baked_test <- bake(prepped, new_data = testing_data)
baked_test
```

## Modeling
\tiny
```{r message=FALSE}
glm_spec <- logistic_reg() %>%
  set_engine("glm") %>%
  set_mode("classification")

rf_spec <- rand_forest() %>%
  set_engine("ranger") %>%
  set_mode("classification")
```

## Cross-validation
```{r echo=FALSE}
knitr::include_graphics(here("images/cross_validation.png"))
```

## Cross-validation
\tiny
```{r}
validation_splits <- vfold_cv(juiced_train, v = 5, strata = survived)
validation_splits

# Alternatives
# ?loo_cv - Leave-One-Out CV
# ?mc_cv - Monte-Carlo CV
# ?nested_cv - Nested or Double CV
```

[Cross-Validation Techniques](https://scikit-learn.org/stable/modules/cross_validation.html)

## Cross-validation
\tiny
```{r}
cv_results <- list(
  glm = fit_resamples(
    glm_spec,
    survived ~ ., 
    validation_splits,
    control = control_resamples(save_pred = T)
    ),
  rf = fit_resamples(
    rf_spec,
    survived ~ ., 
    validation_splits,
    control = control_resamples(save_pred = T)
    )
)

cv_results$glm
```

## Cross-validation
\tiny
```{r}
cv_results$glm %>%
  unnest(.predictions)
```

## Cross-validation results
\tiny
```{r}
roc <- cv_results %>%
  map(~ unnest(.x, .predictions)) %>%
  map2(names(.), ~ mutate(.x, model = .y)) %>%
  bind_rows() %>%
  group_by(model) %>%
  roc_curve(survived, .pred_1) 

roc
```

## Cross-validation results
\tiny
```{r echo=FALSE, fig.align='center', out.width='80%'}
roc %>%
  autoplot()
```

## Cross-validation results
\tiny
```{r}
cv_results %>%
  map(~ collect_metrics(.x))
```

## Final model fit
\tiny
```{r}
rf_fit <- rf_spec %>%
  fit(survived ~ ., data = juiced_train)

rf_fit

rf_fit %>%
  predict(new_data = baked_test, type = "prob") %>%
  mutate(true_label = baked_test$survived) %>%
  roc_auc(true_label, .pred_1)
```

## Pipeline
\tiny
```{r}
pipeline <- workflow() %>% 
  add_recipe(blueprint) %>% 
  add_model(rf_spec)

pipeline_fit <- fit(pipeline, data = training_data)
```

## Pipeline
\tiny
```{r}
pipeline_fit
```

## Pipeline
\tiny
```{r}
predict(pipeline_fit, testing_data)
```

## Recommended resources
\tiny

- [tidymodels website](https://www.tidymodels.org/)
- [Hands-On Machine Learning with R](https://bradleyboehmke.github.io/HOML/)
- [Julia Silge's youtube channel](https://www.youtube.com/channel/UCTTBgWyJl2HrrhQOOc710kA)
- [Rebecca Barter's blog](http://www.rebeccabarter.com/blog/)


## Exercise
```{r echo=FALSE}
knitr::include_graphics(here("images/michael_theoffice.png"))
```

## Exercise - the office
\tiny
```{r}
library(textrecipes)
library(schrute)

df <- schrute::theoffice
glimpse(df)
```

## Exercise - the office
\tiny
```{r}
characters <- c("Pam", "Dwight")

mydf <- df %>%
  dplyr::filter(character %in% characters)
```

```{r echo=FALSE, fig.align='center', out.width='80%'}
mydf %>%
  count(character) %>%
  ggplot(aes(x = reorder(character, -n), y = n, fill = character)) +
  geom_col() + 
  theme_minimal() +
  theme(axis.title = element_blank(), legend.position = "none")
```
